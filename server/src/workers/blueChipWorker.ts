// ==== File: server/src/workers/discoveryWorker.ts ====

// TL;DR above. See plan in the assistant message.

import cron from "node-cron";
import axios from "axios";
import knex from "../db/knex";
import { redisClient } from "../redis/redisClient";
import {
  BLUECHIP_MEMES_QUERY,
  xSTOCK_TOKENS_QUERY,
  VERIFIED_LSTS_QUERY,
  AI_TOKENS_QUERY,
  TRENDING_TOKENS_QUERY,
  POPULAR_TOKENS_QUERY,
  COMBINED_TOKEN_METRICS,
  ALMOST_BONDED_QUERY,
  GET_MIGRATED_TOKENS_QUERY,
  NEWLY_CREATED_TOKENS_QUERY,
  metadataQuery,
  GET_TOKEN_OHLC_QUERY,
  GET_MULTI_TOKENCHART_OHLAC_DATA,
  BATCH_GET_TOTAL_SUPPLY_OF_TOKEN,
  GET_CURRENT_PRICE_OFTOKE_IN_BATCH,
  GET_TOP_HOLDERS_QUERY,
} from "../queries/allQueryFile";
import { sanitizeString } from "../services/bitQueryService";
import { computeLiquidityUSD, getMarketMetricsBatch, getTokenBondingInfo, getTokenHolderStats, getTokenTradeStats, toBigIntSafe, toDecimalSafe } from "../utils/tokenRelatedUtils";
import {
  decodeMetadataBatch,
  Metadata,
  getCreationTimeAndSupplyBatch,
} from "../utils/tokenRelatedUtils"; // assume both exports exist here
import { createPortfolioSnapshot } from "../controllers/pnlController";
import { getCollectInstructionDataSerializer } from "@metaplex-foundation/mpl-core";

// ====================== Config ======================
const BITQUERY_URL = process.env.BITQUERY_URL || "https://streaming.bitquery.io/eap";
const BITQUERY_AUTH_TOKEN = process.env.BITQUERY_AUTH_TOKEN || "ory_at_GVB4S_JW4KylmKz9phcNf8Lfw-nAvnIldmu9y_rbERA.UwC3hBBwTFKIONUHtTZQum1WiAMsP8VCYZFkRD-sXxU";
// console.log("bitquery outh token: ", BITQUERY_AUTH_TOKEN);
const REDIS_TTL = Number(process.env.DISCOVERY_CACHE_TTL ?? 120);
// const DETAIL_BATCH_SIZE = Number(process.env.DETAIL_BATCH_SIZE ?? 5);
const DB_BATCH_SIZE = Number(process.env.DB_BATCH_SIZE ?? 100); // amount per batch insert
const sleep = (ms: number) => new Promise((r) => setTimeout(r, ms));

/* ------------------------
   Helpers
------------------------ */
function chunkArray<T>(arr: T[], size: number): T[][] {
  const out: T[][] = [];
  for (let i = 0; i < arr.length; i += size) out.push(arr.slice(i, i + size));
  return out;
}

function nowISO() {
  return new Date().toISOString();
}

/* ========================
   fetchTokenDetailBatch
   (unchanged, keeps analytics enrichment)
   ======================== */
export async function fetchTokenDetailBatch(tokens: any[]): Promise<any[]> {
  for (let i = 0; i < tokens.length; i += DETAIL_BATCH_SIZE) {
    const batch = tokens.slice(i, i + DETAIL_BATCH_SIZE);
    const mintAddresses = batch.map((t) => t.mint);

    try {
      const res = await axios.post(
        BITQUERY_URL,
        {
          query: COMBINED_TOKEN_METRICS,
          variables: { mintAddresses },
        },
        {
          headers: {
            "Content-Type": "application/json",
            Authorization: `Bearer ${BITQUERY_AUTH_TOKEN}`,
          },
          timeout: 60_000,
        }
      );

      const solanaData = res.data?.data?.Solana;
      if (!solanaData) {
        await sleep(250);
        continue;
      }

      for (const tok of batch) {
        const mint = tok.mint;

        const supplyUpdate = solanaData.TokenSupplyUpdates?.find(
          (u: any) => u.TokenSupplyUpdate?.Currency?.MintAddress === mint
        )?.TokenSupplyUpdate;

        const latestPrice = solanaData.PriceMetrics?.find(
          (p: any) => p.Trade?.Currency?.MintAddress === mint
        )?.Trade?.PriceInUSD;

        let marketcap: number | null = null;
        if ((supplyUpdate?.PostBalanceInUSD ?? 0) > 0) {
          marketcap = supplyUpdate.PostBalanceInUSD;
        } else if (supplyUpdate?.PostBalance && latestPrice) {
          marketcap = Number(supplyUpdate.PostBalance) * Number(latestPrice);
        }

        const priceChangeEntry = solanaData.PriceChange24h?.find(
          (pc: any) => pc.Trade?.Currency?.MintAddress === mint
        );
        const priceChange24h = priceChangeEntry?.PriceChange24hPercent ?? null;

        // const volumeEntry = solanaData.VolumeMetrics?.find(
        //   (v: any) => v.Trade?.Currency?.MintAddress === mint
        // );
        // const volume1h = volumeEntry?.volume_usd_1h ? Number(volumeEntry.volume_usd_1h) : null;

        // const liquidityEntry = solanaData.LiquidityMetrics?.find(
        //   (l: any) => l.Pool?.Market?.BaseCurrency?.MintAddress === mint
        // );
        // const liquidityUSD = liquidityEntry ? computeLiquidityUSD(liquidityEntry.Pool) : null;

        tok.marketcap = marketcap;
        tok.price_change_24h = priceChange24h;
        // tok.volume_24h = volume1h;
        // tok.liquidity = liquidityUSD;
      }
    } catch (err: any) {
      console.warn("‚ö†Ô∏è fetchTokenDetailBatch failed:", err.message);
    }

    // small pause between batches
    await sleep(500);
  }

  return tokens;
}

export async function fetchLaunchpadDetailBatch(
  tokens: any[]
): Promise<any[]> {
  for (let i = 0; i < tokens.length; i += DETAIL_BATCH_SIZE) {
    const batch = tokens.slice(i, i + DETAIL_BATCH_SIZE);
    const mintAddresses = batch.map((t) => t.mint);

    try {
      // --------------------------------------------------
      // 1Ô∏è‚É£ Fetch Combined Metrics (Marketcap + Price Change)
      // --------------------------------------------------
      const res = await axios.post(
        BITQUERY_URL,
        {
          query: COMBINED_TOKEN_METRICS,
          variables: { mintAddresses },
        },
        {
          headers: {
            "Content-Type": "application/json",
            Authorization: `Bearer ${BITQUERY_AUTH_TOKEN}`,
          },
          timeout: 60_000,
        }
      );

      const solanaData = res.data?.data?.Solana;
      if (!solanaData) {
        await sleep(250);
        continue;
      }

      // --------------------------------------------------
      // 2Ô∏è‚É£ Fetch Holder Stats (batch)
      // --------------------------------------------------
      const holderStats = await getTokenHolderStats(mintAddresses);

      // --------------------------------------------------
      // 3Ô∏è‚É£ Fetch Trade Stats (batch)
      // --------------------------------------------------
      const tradeStats = await getTokenTradeStats(mintAddresses);

      // --------------------------------------------------
      // 4Ô∏è‚É£ Fetch Bonding Curve Info (batch) ‚úÖ NEW
      // --------------------------------------------------
      const tokensNeedingBonding = batch.filter(
        (t) => t.bonding_curve_progress == null
      );

      let bondingInfo: any[] = [];

      if (tokensNeedingBonding.length > 0) {
        bondingInfo = await getTokenBondingInfo(
          tokensNeedingBonding.map((t) => t.mint)
        );
      }

      const bondingMap = new Map(
        bondingInfo.map((b) => [b.mintAddress, b])
      );

      // --------------------------------------------------
      // 5Ô∏è‚É£ Merge everything per token
      // --------------------------------------------------
      for (const tok of batch) {
        const mint = tok.mint;

        // ---------- Market Cap ----------
        const supplyUpdate = solanaData.TokenSupplyUpdates?.find(
          (u: any) =>
            u.TokenSupplyUpdate?.Currency?.MintAddress === mint
        )?.TokenSupplyUpdate;

        const latestPrice = solanaData.PriceMetrics?.find(
          (p: any) =>
            p.Trade?.Currency?.MintAddress === mint
        )?.Trade?.PriceInUSD;

        let marketcap: number | null = null;

        if ((supplyUpdate?.PostBalanceInUSD ?? 0) > 0) {
          marketcap = Number(supplyUpdate.PostBalanceInUSD);
        } else if (supplyUpdate?.PostBalance && latestPrice) {
          marketcap =
            Number(supplyUpdate.PostBalance) *
            Number(latestPrice);
        }

        // ---------- Price Change ----------
        const priceChangeEntry =
          solanaData.PriceChange24h?.find(
            (pc: any) =>
              pc.Trade?.Currency?.MintAddress === mint
          );

        tok.marketcap = marketcap;
        tok.price_change_24h =
          priceChangeEntry?.PriceChange24hPercent ?? null;

        // ---------- Holder stats ----------
        tok.holder_count =
          holderStats.holderCount[mint] ?? 0;

        tok.top10_holding_percent =
          holderStats.top10HoldingPercent[mint] ?? 0;

        tok.sniper_holding_percent =
          holderStats.sniperHoldingPercent[mint] ?? 0;

        // ---------- Trade stats ----------
        tok.total_trades =
          tradeStats.totalTrades[mint] ?? 0;

        tok.buy_trades =
          tradeStats.buyTrades[mint] ?? 0;

        tok.sell_trades =
          tradeStats.sellTrades[mint] ?? 0;

        tok.volume_usd_24h =
          tradeStats.volumeUsd24h[mint] ?? 0;

        tok.buy_volume_usd =
          tradeStats.buyVolumeUsd[mint] ?? 0;

        tok.sell_volume_usd =
          tradeStats.sellVolumeUsd[mint] ?? 0;

        // ---------- Bonding curve info ‚úÖ NEW ----------
        const b = bondingMap.get(mint);

        tok.bonding_curve_progress =
          tok.bonding_curve_progress ??
          b?.bondingCurveProgress ??
          null;

        tok.protocol_family =
          tok.protocol_family ??
          b?.protocolFamily ??
          null;

        // tok.bonding_curve_created_on =
        //   b?.creationTime ?? null;
      }
    } catch (err: any) {
      console.warn(
        "‚ö†Ô∏è fetchTokenDetailBatch failed:",
        err.message
      );
    }

    await sleep(500);
  }

  return tokens;
}


/* =========================
   saveTokens - new behavior
   - always upsert to discovery_tokens
   - upsert to tokens ONLY when created_on && total_supply exist
   - B3 semantics: on update, only non-null incoming values overwrite existing
   ========================= */
async function saveTokens(tokens: any[], category: string, redisKey: string) {
  if (!tokens || tokens.length === 0) return;

  // Step 1: Basic normalization
  tokens = tokens.map((t) => ({
    mint: t.mint,
    name: t.name ?? null,
    symbol: t.symbol ?? null,
    uri: t.uri ?? null,
    image: t.image ?? null,
    marketcap: t.marketcap ?? null,
    price_change_24h: t.price_change_24h ?? null,
    volume_24h: t.volume_24h ?? null,
    liquidity: t.liquidity ?? null,
    updated_at: new Date(),
  }));

  // Step 2: Decode metadata in batch
  const uris = tokens.map((t) => t.uri);
  let metadatas: (Metadata | null)[] = [];
  try {
    metadatas = await decodeMetadataBatch(uris);
  } catch (err: any) {
    console.warn("‚ö†Ô∏è decodeMetadataBatch error:", err.message);
    metadatas = tokens.map(() => null);
  }

  tokens.forEach((t, i) => {
    const meta = metadatas[i] ?? null;
    if (meta) {
      if (meta.image) t.image = meta.image;
      t.description = meta.description ?? null;

      const socials: Record<string, string> = {};
      if (meta.twitter) socials.twitter = meta.twitter;
      if (meta.telegram) socials.telegram = meta.telegram;
      if (meta.website) socials.website = meta.website;

      t.socials = Object.keys(socials).length ? socials : null;
      t.metadata_created_on = meta.createdOn ?? null;
    } else {
      t.description = null;
      t.socials = null;
      t.metadata_created_on = null;
    }
  });

  // Step 3: Fetch creation time + supply in batch
  const mintAddresses = tokens.map((t) => t.mint);
  let creationSupplyMap: Record<string, { created_on: string | null; total_supply: number | null }> = {};

  try {
    creationSupplyMap = await getCreationTimeAndSupplyBatch(mintAddresses);
  } catch (err: any) {
    console.error("‚ùå getCreationTimeAndSupplyBatch error:", err.message);
  }

  // Step 4: Build DB rows
  const discoveryRows: any[] = [];
  const tokensRows: any[] = [];

  for (const t of tokens) {
    const cs = creationSupplyMap[t.mint] ?? { created_on: null, total_supply: null };

    // Always push discovery row
    discoveryRows.push({
      mint: t.mint,
      category,
      name: t.name,
      symbol: t.symbol,
      uri: t.uri,
      image: t.image,
      marketcap: t.marketcap,
      price_change_24h: t.price_change_24h,
      volume_24h: t.volume_24h,
      liquidity: t.liquidity,
      updated_at: new Date(),
    });

    // NEW LOGIC: Always push token row
    tokensRows.push({
      mint_address: t.mint,
      name: t.name ?? "Unknown",
      symbol: t.symbol ?? "UNKNOWN",
      image: t.image ?? null,
      uri: t.uri ?? null,
      description: t.description ?? null,
      socials: t.socials ?? {},
      total_supply: cs.total_supply ?? null,          // allow null
      created_on: cs.created_on ?? null,              // allow null
      last_updated: new Date(),
    });
  }

  // Step 5: DB writes in transaction
  const trx = await knex.transaction();
  try {
    // discovery_tokens upserts
    const discoveryChunks = chunkArray(discoveryRows, DB_BATCH_SIZE);
    for (const chunk of discoveryChunks) {
      await trx("discovery_tokens")
        .insert(chunk)
        .onConflict(["mint", "category"])
        .merge({
          name: trx.raw("EXCLUDED.name"),
          symbol: trx.raw("EXCLUDED.symbol"),
          uri: trx.raw("EXCLUDED.uri"),
          image: trx.raw("EXCLUDED.image"),
          marketcap: trx.raw("EXCLUDED.marketcap"),
          price_change_24h: trx.raw("EXCLUDED.price_change_24h"),
          volume_24h: trx.raw("EXCLUDED.volume_24h"),
          liquidity: trx.raw("EXCLUDED.liquidity"),
          updated_at: trx.raw("EXCLUDED.updated_at"),
        });
    }

    // tokens upsert (now includes ALL tokens)
    if (tokensRows.length) {
      const tokenChunks = chunkArray(tokensRows, DB_BATCH_SIZE);

      for (const chunk of tokenChunks) {
        const columns = [
          "mint_address",
          "name",
          "symbol",
          "image",
          "uri",
          "description",
          "socials",
          "total_supply",
          "created_on",
          "last_updated",
        ];

        const valuesSql: string[] = [];
        const bindings: any[] = [];

        for (const row of chunk) {
          valuesSql.push(`(${columns.map(() => "?").join(",")})`);
          bindings.push(
            row.mint_address,
            row.name,
            row.symbol,
            row.image,
            row.uri,
            row.description,
            JSON.stringify(row.socials ?? {}),
            row.total_supply,
            row.created_on,
            row.last_updated
          );
        }

        const insertSql = `
          INSERT INTO tokens (${columns.join(",")})
          VALUES ${valuesSql.join(",")}
          ON CONFLICT (mint_address) DO UPDATE SET
            name = EXCLUDED.name,
            symbol = EXCLUDED.symbol,
            image = COALESCE(EXCLUDED.image, tokens.image),
            uri = COALESCE(EXCLUDED.uri, tokens.uri),
            description = COALESCE(EXCLUDED.description, tokens.description),
            socials = CASE
              WHEN COALESCE(EXCLUDED.socials::text, '') <> '{}' THEN EXCLUDED.socials
              ELSE tokens.socials
            END,
            total_supply = EXCLUDED.total_supply,
            created_on = EXCLUDED.created_on,
            last_updated = NOW()
        `;

        await trx.raw(insertSql, bindings);
      }
    }

    await trx.commit();
  } catch (err: any) {
    await trx.rollback();
    console.error("‚ùå DB save error:", category, err.message);
  }

  // Step 6: Cache
  try {
    await redisClient.set(redisKey, JSON.stringify(tokens), { EX: REDIS_TTL });
  } catch (err: any) {
    console.error("‚ùå Redis error:", err.message);
  }
}



/// ======================================================
// MAIN UPSERT FOR LAUNCHPAD + TOKENS + TOKEN_STATS
// ======================================================
async function saveLaunchpadTokens(
  tokens: any[],
  category: string,
  redisKey: string
) {
  if (!tokens || !tokens.length) return;

  // --------------------------------------------------
  // Normalize tokens
  // --------------------------------------------------
  tokens = tokens.map((t) => ({
    mint: t.mint,
    category,

    name: t.name ?? null,
    symbol: t.symbol ?? null,
    uri: t.uri ?? null,
    image: t.image ?? null,

    marketcap: t.marketcap ?? null,
    price_change_24h: t.price_change_24h ?? null,

    holders: t.holder_count ?? null,
    txns: t.total_trades ?? null,
    buy_trades: t.buy_trades ?? null,
    sell_trades: t.sell_trades ?? null,
    volume: t.volume_usd_24h ?? null,

    buy_volume: t.buy_volume_usd ?? null,
    sell_volume: t.sell_volume_usd ?? null,

    holding_top_10: t.top10_holding_percent ?? null,
    holding_snipers: t.sniper_holding_percent ?? null,

    // ‚úÖ NEW
    bonding_curve_progress: t.bonding_curve_progress ?? null,
    protocol_family: t.protocol_family ?? null,
    // bonding_curve_created_on: t.bonding_curve_created_on ?? null,

    time: t.bonding_curve_created_on ?? null,
    updated_at: new Date(),
  }));

  // --------------------------------------------------
  // Metadata decode (unchanged)
  // --------------------------------------------------
  let metas: any[] = [];
  try {
    metas = await decodeMetadataBatch(tokens.map((t) => t.uri));
  } catch {
    metas = tokens.map(() => null);
  }

  tokens.forEach((t, i) => {
    const m = metas[i];
    if (!m) return;

    t.image = m.image ?? t.image;
    t.social_twitter = m.twitter ?? null;
    t.social_telegram = m.telegram ?? null;
    t.social_website = m.website ?? null;
    t.social_tiktok = m.tiktok ?? null;
  });

  // --------------------------------------------------
  // Creation time / supply batch (unchanged)
  // --------------------------------------------------
  let supplyData: Record<string, any> = {};
  try {
    supplyData = await getCreationTimeAndSupplyBatch(
      tokens.map((t) => t.mint)
    );
  } catch {
    supplyData = {};
  }

  // --------------------------------------------------
  // Build DB rows
  // --------------------------------------------------
  const launchpadRows: any[] = [];
  const tokensRows: any[] = [];
  const tokenStatsRows: any[] = [];

  for (const t of tokens) {
    const cs = supplyData[t.mint] ?? {};

    launchpadRows.push({
      mint: t.mint,
      category,
      name: t.name,
      symbol: t.symbol,
      uri: t.uri,
      image: t.image,
      time: t.time,

      social_twitter: t.social_twitter,
      social_telegram: t.social_telegram,
      social_website: t.social_website,

      marketcap: toDecimalSafe(t.marketcap),
      volume: toDecimalSafe(t.volume),

      holders: toBigIntSafe(t.holders),
      txns: toBigIntSafe(t.txns),

      holding_top_10: toDecimalSafe(t.holding_top_10),
      holding_snipers: toDecimalSafe(t.holding_snipers),

      // ‚úÖ NEW DB FIELDS
      bonding_curve_progress: toDecimalSafe(
        t.bonding_curve_progress
      ),
      protocol_family: t.protocol_family,
      // bonding_curve_created_on:
      //   t.bonding_curve_created_on,

      updated_at: new Date(),
    });

    tokensRows.push({
      mint_address: t.mint,
      name: t.name,
      symbol: t.symbol,
      uri: t.uri,
      image: t.image,
      description: null,
      socials: {
        twitter: t.social_twitter,
        telegram: t.social_telegram,
        website: t.social_website,
      },
      total_supply: cs.total_supply ?? null,
      created_on: cs.created_on ?? null,
      last_updated: new Date(),
    });

    tokenStatsRows.push({
      token_mint: t.mint,

      market_cap: toDecimalSafe(t.marketcap),
      volume_24h: toDecimalSafe(t.volume),

      holders_count: toBigIntSafe(t.holders),
      tx_count: toBigIntSafe(t.txns),

      total_supply: toBigIntSafe(cs.total_supply),
      created_on: cs.created_on ?? null,

      price_change_24h: toDecimalSafe(t.price_change_24h),

      buy_volume: toDecimalSafe(t.buy_volume),
      sell_volume: toDecimalSafe(t.sell_volume),
      num_buys: toBigIntSafe(t.buy_trades),
      num_sells: toBigIntSafe(t.sell_trades),

      "top_10_holders_%": toDecimalSafe(t.holding_top_10),
      holding_snipers: toDecimalSafe(t.holding_snipers),

      fetched_at: new Date(),
    });
  }

  // --------------------------------------------------
  // DB UPSERTS (unchanged)
  // --------------------------------------------------
  const trx = await knex.transaction();

  try {
    for (const ch of chunkArray(launchpadRows, 100)) {
      await trx("launchpad_tokens")
        .insert(ch)
        .onConflict(["mint", "category"])
        .merge();
    }

    for (const ch of chunkArray(tokensRows, 100)) {
      await trx("tokens")
        .insert(ch)
        .onConflict("mint_address")
        .merge();
    }

    for (const ch of chunkArray(tokenStatsRows, 100)) {
      await trx("token_stats").insert(ch);
    }

    await trx.commit();
  } catch (err) {
    await trx.rollback();
    console.error("‚ùå saveLaunchpadTokens failed:", err);
  }

  // --------------------------------------------------
  // Redis cache
  // --------------------------------------------------
  try {
    await redisClient.set(redisKey, JSON.stringify(tokens), {
      EX: 120,
    });
  } catch { }
}



// ======================================================
// WORKER FETCHERS (3 new ones)
// ======================================================

// ---------- ALMOST BONDED ----------
// ---------- ALMOST BONDED ----------
async function fetchAlmostBondedNow() {
  console.log("üîÑ Fetching Almost Bonded Tokens...");

  try {
    const res = await axios.post(
      BITQUERY_URL,
      { query: ALMOST_BONDED_QUERY },
      {
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${BITQUERY_AUTH_TOKEN}`,
        },
        timeout: 120_000,
      }
    );

    const pools = res.data?.data?.Solana?.DEXPools ?? [];
    const tokens: any[] = [];

    for (const p of pools) {
      const base = p?.Pool?.Market?.BaseCurrency ?? {};
      const mint = base.MintAddress;
      if (!mint) continue;

      tokens.push({
        mint,
        name: base.Name ?? null,
        symbol: base.Symbol ?? null,
        uri: base.Uri ?? null,
        bondingProgress: p.Bonding_Curve_Progress_Percentage ?? null,
        protocolFamily: p?.Pool?.Dex?.ProtocolFamily ?? null,
      });
    }

    // Apply bonding filter (65%‚Äì97%)
    const filtered = tokens.filter(
      (t) => t.bondingProgress >= 65 && t.bondingProgress <= 97
    );

    await fetchLaunchpadDetailBatch(filtered);
    await saveLaunchpadTokens(filtered, "almost_bonded", "launchpad-almost-bonded");

    console.log(`‚úÖ Saved ${filtered.length} almost bonded tokens`);

  } catch (err: any) {
    console.error("‚ùå fetchAlmostBondedNow error:", err.message);
  }
}


// ---------- MIGRATED ----------
async function fetchMigratedNow() {
  console.log("üîÑ Fetching Migrated Tokens...");

  const TOKEN_PROGRAM_ID =
    "TokenkegQfeZyiNwAJbNbGKPFXCWuBvf9Ss623VQ5DA";

  try {
    // 1Ô∏è‚É£ Fetch migrated instructions
    const response = await axios.post(
      BITQUERY_URL,
      { query: GET_MIGRATED_TOKENS_QUERY },
      {
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${BITQUERY_AUTH_TOKEN}`,
        },
        timeout: 120_000,
      }
    );

    const instructions =
      response.data?.data?.Solana?.Instructions ?? [];

    // 2Ô∏è‚É£ Extract migrated mints (ROUTE LOGIC)
    const mintMethodMap = new Map<string, string>();

    for (const instr of instructions) {
      const method =
        instr?.Instruction?.Program?.Method ?? "";
      const accounts =
        instr?.Instruction?.Accounts ?? [];

      const candidates = accounts.filter(
        (acc: any) =>
          acc?.Token?.Mint &&
          acc?.Token?.Owner === TOKEN_PROGRAM_ID &&
          acc?.Token?.ProgramId === TOKEN_PROGRAM_ID
      );

      if (!candidates.length) continue;

      const mint =
        method === "migrate_meteora_damm"
          ? candidates[1]?.Token?.Mint ||
          candidates[0]?.Token?.Mint
          : candidates[0]?.Token?.Mint;

      if (!mint) continue;

      mintMethodMap.set(mint, method);
    }

    const mintAddresses = [...mintMethodMap.keys()];
    console.log(" mint addresses: ", mintAddresses[3], mintAddresses.length);
    if (!mintAddresses.length) {
      console.log("‚ö†Ô∏è No migrated tokens found");
      return;
    }

    // 3Ô∏è‚É£ BATCH metadataQuery (THIS WAS THE MISSING STEP)
    const metaResponse = await axios.post(
      BITQUERY_URL,
      {
        query: metadataQuery,
        variables: { mintAddresses },
      },
      {
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${BITQUERY_AUTH_TOKEN}`,
        },
        timeout: 60_000,
      }
    );

    const pools =
      metaResponse.data?.data?.Solana?.DEXPools ?? [];

    // 4Ô∏è‚É£ Build mint ‚Üí metadata map
    const metaMap = new Map<string, any>();

    for (const p of pools) {
      const base =
        p?.Pool?.Market?.BaseCurrency;

      if (!base?.MintAddress || !base?.Name) continue;

      metaMap.set(base.MintAddress, {
        name: base.Name,
        symbol: base.Symbol ?? null,
        uri: base.Uri ?? null,
      });
    }

    // 5Ô∏è‚É£ Build final tokens (NO NULL NAME)
    const tokens: any[] = [];

    for (const mint of mintAddresses) {
      const meta = metaMap.get(mint);
      if (!meta) continue;

      tokens.push({
        mint,
        name: meta.name,
        symbol: meta.symbol,
        uri: meta.uri,
        method: mintMethodMap.get(mint),
      });
    }

    if (!tokens.length) {
      console.log("‚ö†Ô∏è No hydrated migrated tokens");
      return;
    }

    // 6Ô∏è‚É£ Continue normal pipeline
    await fetchLaunchpadDetailBatch(tokens);
    await saveLaunchpadTokens(
      tokens,
      "migrated",
      "launchpad-migrated"
    );

    console.log(`‚úÖ Saved ${tokens.length} migrated tokens`);
  } catch (err: any) {
    console.error("‚ùå fetchMigratedNow error:", err.message);
  }
}





// ---------- NEWLY CREATED ----------
async function fetchNewlyCreatedNow() {
  console.log("üîÑ Fetching Newly Created Tokens...");

  try {
    const res = await axios.post(
      BITQUERY_URL,
      { query: NEWLY_CREATED_TOKENS_QUERY },
      {
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${BITQUERY_AUTH_TOKEN}`,
        },
        timeout: 120_000,
      }
    );

    const instr = res.data?.data?.Solana?.Instructions ?? [];
    const list: any[] = [];

    for (const i of instr) {
      const accounts = i.Instruction?.Accounts ?? [];
      const mintAcc = accounts.find((a: any) => a?.Token?.Mint);
      const mint = mintAcc?.Token?.Mint;
      if (!mint) continue;

      const arg = i.Instruction?.Program?.Arguments?.find(
        (a: any) => a.Name === "createMetadataAccountArgsV3"
      );

      let metaData = null;
      try {
        metaData = arg?.Value?.json ? JSON.parse(arg.Value.json) : null;
      } catch { }

      const data = metaData?.data ?? {};

      list.push({
        mint,
        name: data?.name ?? null,
        symbol: data?.symbol ?? null,
        uri: data?.uri ?? null,
      });
    }

    console.log("list of newly created tokens: ", list);
    await fetchLaunchpadDetailBatch(list);
    console.log("list1: ", list[1]);
    await saveLaunchpadTokens(list, "newly_created", "launchpad-newly-created");
    console.log("list2: ", list[1]);
    console.log(`‚úÖ Saved ${list.length} newly created tokens`);

  } catch (err: any) {
    console.error("‚ùå fetchNewlyCreatedNow error:", err.message);
  }
}



/* =========================
   Category Fetchers
   (minor changes: remove local decodeMetadata usage; rely on saveTokens)
   ========================= */

// ----------------------
// Bluechip Memes
// ----------------------
async function fetchBluechipMemesNow() {
  console.log("üîÑ Fetching Bluechip Memes...");
  try {
    const response = await axios.post(
      BITQUERY_URL,
      { query: BLUECHIP_MEMES_QUERY },
      {
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${BITQUERY_AUTH_TOKEN}`,
        },
        timeout: 120_000,
      }
    );

    const updates = response.data?.data?.Solana?.TokenSupplyUpdates ?? [];
    const tokens: any[] = [];

    for (const entry of updates) {
      const update = entry.TokenSupplyUpdate ?? {};
      const currency = update.Currency ?? {};
      const mint = currency.MintAddress;
      if (!mint) continue;

      tokens.push({
        mint,
        name: sanitizeString(currency.Name),
        symbol: sanitizeString(currency.Symbol),
        uri: sanitizeString(currency.Uri),
        image: null,
        marketcap: update.Marketcap ?? null,
        price_change_24h: null,
        volume_24h: null,
        liquidity: null,
        updated_at: new Date(),
      });
    }

    await fetchTokenDetailBatch(tokens);
    await saveTokens(tokens, "bluechip_meme", "bluechip-memes");
    console.log(`‚úÖ Saved ${tokens.length} bluechip memes`);
  } catch (err: any) {
    console.error("‚ùå fetchBluechipMemesNow error:", err.message);
  }
}

// ----------------------
// xStock
// ----------------------
async function fetchXStockNow() {
  console.log("üîÑ Fetching xStock tokens...");
  try {
    const response = await axios.post(
      BITQUERY_URL,
      { query: xSTOCK_TOKENS_QUERY },
      {
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${BITQUERY_AUTH_TOKEN}`,
        },
      }
    );

    const trades = response.data?.data?.Solana?.DEXTradeByTokens ?? [];
    const seen = new Map<string, any>();
    for (const entry of trades) {
      const c = entry.Trade?.Currency ?? {};
      const mint = c.MintAddress;
      if (!mint || seen.has(mint)) continue;
      seen.set(mint, {
        mint,
        name: sanitizeString(c.Name),
        symbol: sanitizeString(c.Symbol),
        uri: sanitizeString(c.Uri),
        image: null,
        marketcap: null,
        price_change_24h: null,
        volume_24h: null,
        liquidity: null,
        updated_at: new Date(),
      });
    }

    const tokens = Array.from(seen.values());
    await fetchTokenDetailBatch(tokens);
    await saveTokens(tokens, "xstock", "xstock-tokens");
    console.log(`‚úÖ Saved ${tokens.length} xStock tokens`);
  } catch (err: any) {
    console.error("‚ùå fetchXStockNow error:", err.message);
  }
}

// ----------------------
// LSTs
// ----------------------
async function fetchLstsNow() {
  console.log("üîÑ Fetching Verified LSTs...");
  try {
    const response = await axios.post(
      BITQUERY_URL,
      { query: VERIFIED_LSTS_QUERY },
      {
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${BITQUERY_AUTH_TOKEN}`,
        },
      }
    );

    const trades = response.data?.data?.Solana?.DEXTradeByTokens ?? [];
    const seen = new Map<string, any>();
    for (const entry of trades) {
      const c = entry.Trade?.Currency ?? {};
      const mint = c.MintAddress;
      if (!mint || seen.has(mint)) continue;
      seen.set(mint, {
        mint,
        name: sanitizeString(c.Name),
        symbol: sanitizeString(c.Symbol),
        uri: sanitizeString(c.Uri),
        image: null,
        marketcap: null,
        price_change_24h: null,
        volume_24h: null,
        liquidity: null,
        updated_at: new Date(),
      });
    }

    const tokens = Array.from(seen.values());
    await fetchTokenDetailBatch(tokens);
    await saveTokens(tokens, "lsts", "lsts-tokens");
    console.log(`‚úÖ Saved ${tokens.length} LST tokens`);
  } catch (err: any) {
    console.error("‚ùå fetchLstsNow error:", err.message);
  }
}

// ----------------------
// AI Tokens
// ----------------------
async function fetchAiNow() {
  console.log("üîÑ Fetching AI tokens...");
  try {
    const response = await axios.post(
      BITQUERY_URL,
      { query: AI_TOKENS_QUERY },
      {
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${BITQUERY_AUTH_TOKEN}`,
        },
      }
    );

    const trades = response.data?.data?.Solana?.DEXTradeByTokens ?? [];
    const seen = new Map<string, any>();
    for (const entry of trades) {
      const c = entry.Trade?.Currency ?? {};
      const mint = c.MintAddress;
      if (!mint || seen.has(mint)) continue;
      seen.set(mint, {
        mint,
        name: sanitizeString(c.Name),
        symbol: sanitizeString(c.Symbol),
        uri: sanitizeString(c.Uri),
        image: null,
        marketcap: null,
        price_change_24h: null,
        volume_24h: null,
        liquidity: null,
        updated_at: new Date(),
      });
    }

    const tokens = Array.from(seen.values());
    await fetchTokenDetailBatch(tokens);
    await saveTokens(tokens, "ai", "ai-tokens");
    console.log(`‚úÖ Saved ${tokens.length} AI tokens`);
  } catch (err: any) {
    console.error("‚ùå fetchAiNow error:", err.message);
  }
}

// ----------------------
// Trending
// ----------------------
async function fetchTrendingNow() {
  console.log("üîÑ Fetching Trending tokens...");
  try {
    const response = await axios.post(
      BITQUERY_URL,
      { query: TRENDING_TOKENS_QUERY },
      {
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${BITQUERY_AUTH_TOKEN}`,
        },
      }
    );

    const solana = response.data?.data?.Solana;
    if (!solana) return;

    const frames = [solana.trending_1min, solana.trending_5min, solana.trending_30min, solana.trending_1hour].filter(Boolean);
    const tokenMap = new Map<string, any[]>();

    frames.forEach((frame: any[], idx: number) => {
      frame.forEach((entry: any) => {
        const c = entry.Trade?.Currency;
        if (!c?.MintAddress) return;
        if (!tokenMap.has(c.MintAddress)) tokenMap.set(c.MintAddress, []);
        tokenMap.get(c.MintAddress)!.push({ frameIndex: idx, uniqueTraders: entry.tradesCountWithUniqueTraders, volume: entry.traded_volume, trades: entry.trades, currency: c });
      });
    });

    const trending: any[] = [];
    const seenMints = new Set<string>();

    for (const [mint, metrics] of tokenMap) {
      metrics.sort((a, b) => a.frameIndex - b.frameIndex);
      let isTrending = false;
      for (let i = 1; i < metrics.length; i++) {
        if (metrics[i].uniqueTraders > metrics[i - 1].uniqueTraders || metrics[i].volume > metrics[i - 1].volume || metrics[i].trades > metrics[i - 1].trades) {
          isTrending = true;
          break;
        }
      }
      if (isTrending && !seenMints.has(mint)) {
        seenMints.add(mint);
        const c = metrics[0].currency;
        trending.push({
          mint,
          name: sanitizeString(c.Name),
          symbol: sanitizeString(c.Symbol),
          uri: sanitizeString(c.Uri),
          image: null,
          marketcap: null,
          price_change_24h: null,
          volume_24h: null,
          liquidity: null,
          updated_at: new Date(),
        });
      }
    }

    await fetchTokenDetailBatch(trending);
    await saveTokens(trending, "trending", "trending-tokens");
    console.log(`‚úÖ Saved ${trending.length} trending tokens`);
  } catch (err: any) {
    console.error("‚ùå fetchTrendingNow error:", err.message);
  }
}

// src/workers/fetchTokenChartNow.ts

const INTERVAL_MINUTES = 5;
const INTERVAL_LABEL = "5m";

export async function fetchTokenChartNow() {
  console.log("üìä fetchTokenChartNow started");

  const tokens = await knex("tokens")
    .where({ is_active: true })
    .pluck("mint_address");

  if (!tokens.length) return;
  console.log("tokens length: ", tokens.length);

  const tokenBatches = chunkArray(tokens, DETAIL_BATCH_SIZE);

  for (const mintAddresses of tokenBatches) {
    try {
      const response = await axios.post(
        BITQUERY_URL,
        {
          query: GET_MULTI_TOKENCHART_OHLAC_DATA,
          variables: {
            mintAddresses,
            solMint: "So11111111111111111111111111111111111111112",
            limit: 300,
            intervalInMinutes: INTERVAL_MINUTES,
          },
        },
        {
          headers: {
            Authorization: `Bearer ${BITQUERY_AUTH_TOKEN}`,
          },
        }
      );

      const rows =
        response.data?.data?.Solana?.DEXTradeByTokens ?? [];

      if (!rows.length) continue;

      const candles = rows.map((r: any) => ({
        token_mint: r.Trade.Currency.MintAddress,
        interval: INTERVAL_LABEL,
        time: Math.floor(new Date(r.Block.Timefield).getTime() / 1000),
        open: Number(r.Trade.open),
        high: Number(r.Trade.high),
        low: Number(r.Trade.low),
        close: Number(r.Trade.close),
        volume: Number(r.volume),
      }));

      const dbBatches = chunkArray(candles, DB_BATCH_SIZE);

      for (const batch of dbBatches) {
        await knex("token_chart")
          .insert(batch)
          .onConflict(["token_mint", "interval", "time"])
          .merge();
      }

      await sleep(300); // small pause to respect Bitquery limits
    } catch (err: any) {
      console.error("‚ùå chart batch failed:", err.message);
    }
  }

  // ‚úÖ retention: keep ~1 month (31 days)
  const ONE_MONTH_SECONDS = 31 * 24 * 60 * 60;

  await knex("token_chart")
    .where(
      "time",
      "<",
      Math.floor(Date.now() / 1000) - ONE_MONTH_SECONDS
    )
    .delete();
}
const DETAIL_BATCH_SIZE = 20;

type ActiveTokenRow = {
  mint_address: string;
};

async function runTokenStatsWorker(): Promise<void> {
  const tokens: ActiveTokenRow[] = await knex("tokens")
    .select("mint_address")
    .where("is_active", true);

  for (let i = 0; i < tokens.length; i += DETAIL_BATCH_SIZE) {
    const batch = tokens.slice(i, i + DETAIL_BATCH_SIZE);
    const mintAddresses = batch.map(t => t.mint_address);

    try {
      const [
        marketMetrics,
        tradeStats,
        holderStats,
        creationSupply,
      ] = await Promise.all([
        getMarketMetricsBatch(mintAddresses),
        getTokenTradeStats(mintAddresses),
        getTokenHolderStats(mintAddresses),
        getCreationTimeAndSupplyBatch(mintAddresses),
      ]);

      const rows = mintAddresses.map((mint) => ({
        token_mint: mint,

        market_cap: marketMetrics[mint]?.market_cap ?? null,
        price_change_24h: marketMetrics[mint]?.price_change_24h ?? null,

        volume_24h: tradeStats.volumeUsd24h?.[mint] ?? null,
        buy_volume: tradeStats.buyVolumeUsd?.[mint] ?? null,
        sell_volume: tradeStats.sellVolumeUsd?.[mint] ?? null,

        tx_count: tradeStats.totalTrades?.[mint] ?? null,
        num_buys: tradeStats.buyTrades?.[mint] ?? null,
        num_sells: tradeStats.sellTrades?.[mint] ?? null,

        holders_count: holderStats.holderCount?.[mint] ?? null,
        "top_10_holders_%": holderStats.top10HoldingPercent?.[mint] ?? null,
        holding_snipers: holderStats.sniperHoldingPercent?.[mint] ?? null,

        total_supply: creationSupply[mint]?.total_supply ?? null,
        created_on: creationSupply[mint]?.created_on ?? null,

        fetched_at: knex.fn.now(),
      }));

      await knex("token_stats")
        .insert(rows)
        .onConflict("token_mint")
        .merge();

    } catch (err) {
      console.error("‚ùå Token stats batch failed:", err);
    }
  }
}

async function runTokenHoldersWorker(): Promise<void> {
  const tokens: ActiveTokenRow[] = await knex("tokens")
    .select("mint_address")
    .where("is_active", true);

  console.log("tokens lenght: ", tokens.length);
  for (let i = 0; i < tokens.length; i += DETAIL_BATCH_SIZE) {
    const batch = tokens.slice(i, i + DETAIL_BATCH_SIZE);
    const mintAddresses = batch.map(t => t.mint_address);

    try {
      // --------------------------------------------------
      // 1Ô∏è‚É£ Fetch top holders
      // --------------------------------------------------
      const holdersRes = await axios.post(
        BITQUERY_URL,
        {
          query: GET_TOP_HOLDERS_QUERY,
          variables: { mintAddresses },
        },
        {
          headers: {
            Authorization: `Bearer ${BITQUERY_AUTH_TOKEN}`,
          },
          timeout: 60000,
        }
      );

      const balanceUpdates =
        holdersRes.data?.data?.Solana?.BalanceUpdates ?? [];

      if (!balanceUpdates.length) continue;

      // --------------------------------------------------
      // 2Ô∏è‚É£ Fetch prices
      // --------------------------------------------------
      const priceRes = await axios.post(
        BITQUERY_URL,
        {
          query: GET_CURRENT_PRICE_OFTOKE_IN_BATCH,
          variables: { mintAddresses },
        },
        {
          headers: {
            Authorization: `Bearer ${BITQUERY_AUTH_TOKEN}`,
          },
          timeout: 60000,
        }
      );

      const priceRows =
        priceRes.data?.data?.Solana?.PriceMetrics ?? [];

      const priceByMint: Record<string, number> = {};
      for (const p of priceRows) {
        const mint = p.Trade.Currency.MintAddress;
        const priceUsd = Number(p.Trade.PriceInUSD ?? 0);
        priceByMint[mint] = priceUsd;
      }

      // --------------------------------------------------
      // 3Ô∏è‚É£ Fetch total supply
      // --------------------------------------------------
      const supplyRes = await axios.post(
        BITQUERY_URL,
        {
          query: BATCH_GET_TOTAL_SUPPLY_OF_TOKEN,
          variables: { mintAddresses },
        },
        {
          headers: {
            Authorization: `Bearer ${BITQUERY_AUTH_TOKEN}`,
          },
          timeout: 60000,
        }
      );

      const supplyRows =
        supplyRes.data?.data?.Solana?.TokenSupplyUpdates ?? [];

      const supplyByMint: Record<string, number> = {};
      for (const row of supplyRows) {
        const mint = row.TokenSupplyUpdate.Currency.MintAddress;
        supplyByMint[mint] = Number(row.TokenSupplyUpdate.PostBalance) || 0;
      }

      // --------------------------------------------------
      // 4Ô∏è‚É£ Build DB rows
      // --------------------------------------------------
      const rows = balanceUpdates.map((row: any) => {
        const mint = row.BalanceUpdate.Currency.MintAddress;
        const holderAddress = row.BalanceUpdate.Account.Address;

        const holding = Number(row.BalanceUpdate.Holding) || 0;
        const priceUsd = priceByMint[mint] ?? 0;
        const totalSupply = supplyByMint[mint] ?? 0;

        const valueUsd = Number((holding * priceUsd).toFixed(8));
        const holdingPercent =
          totalSupply > 0
            ? Number(((holding / totalSupply) * 100).toFixed(6))
            : 0;

        return {
          token_mint: mint,
          holder_address: holderAddress,
          tokens_holdings: holding,
          value_of_tokens_holdings: valueUsd,
          holding_percent: holdingPercent,
          fetched_at: knex.fn.now(),
        };
      });

      // --------------------------------------------------
      // 5Ô∏è‚É£ UPSERT (no DB load)
      // --------------------------------------------------
      await knex("token_holders")
        .insert(rows)
        .onConflict(["token_mint", "holder_address"])
        .merge();

    console.log(`‚úÖ Saved alltoken holders popular tokens`);
    } catch (err: any) {
      console.error("‚ùå token holders batch failed:", err.message);
    }
  }
}
// ----------------------
// Popular
// ----------------------
async function fetchPopularNow() {
  console.log("üîÑ Fetching Popular tokens...");
  try {
    const response = await axios.post(
      BITQUERY_URL,
      { query: POPULAR_TOKENS_QUERY },
      {
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${BITQUERY_AUTH_TOKEN}`,
        },
      }
    );

    const solana = response.data?.data?.Solana;
    if (!solana) return;

    const frames = [solana.popular_24h, solana.popular_7d].filter(Boolean);
    const tokenMap = new Map<string, any[]>();

    frames.forEach((frame: any[], idx: number) => {
      frame.forEach((entry: any) => {
        const c = entry.Trade?.Currency;
        if (!c?.MintAddress) return;
        if (!tokenMap.has(c.MintAddress)) tokenMap.set(c.MintAddress, []);
        tokenMap.get(c.MintAddress)!.push({ frameIndex: idx, currency: c });
      });
    });

    const popular: any[] = [];
    const seenMints = new Set<string>();

    for (const [mint, metrics] of tokenMap) {
      metrics.sort((a, b) => a.frameIndex - b.frameIndex);
      if (!seenMints.has(mint)) {
        seenMints.add(mint);
        const c = metrics[0].currency;
        popular.push({
          mint,
          name: sanitizeString(c.Name),
          symbol: sanitizeString(c.Symbol),
          uri: sanitizeString(c.Uri),
          image: null,
          marketcap: null,
          price_change_24h: null,
          volume_24h: null,
          liquidity: null,
          updated_at: new Date(),
        });
      }
    }

    await fetchTokenDetailBatch(popular);
    await saveTokens(popular, "popular", "popular-tokens");
    console.log(`‚úÖ Saved ${popular.length} popular tokens`);
  } catch (err: any) {
    console.error("‚ùå fetchPopularNow error:", err.message);
  }
}


async function repairMissingMetadata(): Promise<void> {
  console.log("üõ†Ô∏è Starting metadata repair job...");

  const BATCH_SIZE = 25;

  /* ======================================================
   * STEP 1A ‚Äî FIX TOKENS TABLE (decode + update)
   * ====================================================== */
  console.log("üîç Checking tokens table for missing image/description/socials...");

  const tokensMissing = await knex("tokens")
    .select("mint_address as mint", "uri")
    .where(function () {
      this.whereNull("image")
        .orWhere("image", "")
        .orWhereNull("description")
        .orWhere("description", "");
    });

  console.log("‚û°Ô∏è Missing tokens count:", tokensMissing.length);

  const tokenJobs = tokensMissing.filter((row) => row.uri);

  for (let i = 0; i < tokenJobs.length; i += BATCH_SIZE) {
    const batch = tokenJobs.slice(i, i + BATCH_SIZE);
    const uris = batch.map((b) => b.uri);

    console.log(
      `üü¢ Token decode batch ${i / BATCH_SIZE + 1} (${batch.length} items)...`
    );

    const decoded = await decodeMetadataBatch(uris);

    for (let j = 0; j < batch.length; j++) {
      const req = batch[j];
      const meta = decoded[j];
      if (!meta) continue;

      const socials = {
        telegram: meta.telegram ?? null,
        twitter: meta.twitter ?? null,
        website: meta.website ?? null,
      };

      try {
        await knex("tokens")
          .update({
            image: meta.image ?? null,
            description: meta.description ?? null,
            socials: JSON.stringify(socials),
            last_updated: knex.fn.now(),
          })
          .where({ mint_address: req.mint });
      } catch (err: any) {
        console.error("‚ùå Failed to update token:", req.mint, err.message);
      }
    }
  }

  console.log("‚úÖ Step 1A complete ‚Äî Metadata decoded & stored.");


  /* ======================================================
   * STEP 1B ‚Äî FETCH creation_time + total_supply FOR MISSING TOKENS
   * ====================================================== */
  console.log("‚è≥ Checking tokens missing created_on or total_supply...");

  const tokensMissingCTS = await knex("tokens")
    .select("mint_address as mint")
    .where(function () {
      this.whereNull("created_on")
        .orWhereNull("total_supply");
    });

  console.log("‚û°Ô∏è Tokens missing creation time / supply:", tokensMissingCTS.length);

  const mintList = tokensMissingCTS.map((t) => t.mint);

  for (let i = 0; i < mintList.length; i += BATCH_SIZE) {
    const batch = mintList.slice(i, i + BATCH_SIZE);

    console.log(
      `üü£ Creation/Supply batch ${i / BATCH_SIZE + 1} (${batch.length} items)...`
    );

    try {
      const result = await getCreationTimeAndSupplyBatch(batch);

      for (const mint of batch) {
        const row = result[mint];
        if (!row) continue;

        await knex("tokens")
          .update({
            created_on: row.created_on,
            total_supply: row.total_supply,
            last_updated: knex.fn.now(),
          })
          .where({ mint_address: mint });
      }
    } catch (err: any) {
      console.error("‚ùå Error updating creation/supply batch:", err.message);
    }
  }

  console.log("‚úÖ Step 1B complete ‚Äî Created_on & total_supply updated.");


  /* ======================================================
   * STEP 2 ‚Äî SYNC discovery_tokens USING tokens TABLE (NO DECODING)
   * ====================================================== */
  console.log("üîç Checking discovery_tokens with missing images...");

  const discoveryMissing = await knex("discovery_tokens")
    .select("mint", "category")
    .where(function () {
      this.whereNull("image").orWhere("image", "");
    });

  console.log("‚û°Ô∏è discovery missing count:", discoveryMissing.length);

  for (const row of discoveryMissing) {
    try {
      const tokenData = await knex("tokens")
        .select("image")
        .where({ mint_address: row.mint })
        .first();

      if (!tokenData || !tokenData.image) continue;

      await knex("discovery_tokens")
        .update({
          image: tokenData.image,
          updated_at: knex.fn.now(),
        })
        .where({
          mint: row.mint,
          category: row.category,
        });
    } catch (err: any) {
      console.error(
        "‚ùå Failed updating discovery token:",
        row.mint,
        err.message
      );
    }
  }

  console.log("üéâ ALL metadata repaired successfully.");
}

async function createPortfolioSnapshotsNow(): Promise<void> {
  console.log("üì∏ Creating portfolio snapshots...");

  try {
    const users = await knex("users")
      .where({ is_active: true })
      .select("privy_id", "balance_usd", "pnl_usd");

    for (const user of users) {
      await createPortfolioSnapshot(user.privy_id);
    }

    console.log(`‚úÖ Portfolio snapshots created for ${users.length} users`);
  } catch (err: any) {
    console.error("‚ùå createPortfolioSnapshotsNow error:", err.message);
  }
}



/* ====================== Worker Scheduler ====================== */
export function startDiscoveryWorker() {
  cron.schedule("*/3 * * * *", async () => {
    console.log("üîÑ Discovery worker tick...");
    try {
      // await fetchBluechipMemesNow();
      // await fetchXStockNow();
      // await fetchLstsNow();
      // await fetchAiNow();
      // await fetchTrendingNow();
      // await fetchPopularNow();
      // await repairMissingMetadata();
      // await fetchNewlyCreatedNow();
      // await fetchAlmostBondedNow();
      // await fetchMigratedNow();
      // await fetchTokenChartNow();
      await runTokenHoldersWorker();
      // await createPortfolioSnapshotsNow();
    } catch (err: any) {
      console.error("‚ùå discovery worker tick failed:", err.message);
    }
  });
  console.log("‚è±Ô∏è Discovery worker scheduled: every 3 minutes");
}

if (require.main === module) {
  (async () => {
    if (!redisClient.isOpen) await redisClient.connect();
    startDiscoveryWorker();
  })();
}
